{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> AIA Edge AI 技術班 專案</span>\n",
    "\n",
    "## <span style=\"color:blue\">專案準備資料</span>\n",
    "> - [NVIDIA® Jetson Nano™ JETBOT AI ROBOT KIT](https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetbot-ai-robot-kit/)\n",
    ">   - [Jetbot github](https://github.com/NVIDIA-AI-IOT/jetbot) : 部份內容沒更新到最新版本, 如 https://github.com/NVIDIA-AI-IOT/jetbot/wiki/software-setup 的 image 下載版本已經到 JetPack 4.4.1, 此文還停留在 JetPack 4.3.\n",
    "> - [Jetbot.org](https://jetbot.org/master/getting_started.html)\n",
    ">   - [WaveShare JetBot AI Kit 安裝說明](https://www.waveshare.com/wiki/JetBot_AI_Kit)\n",
    "> - [ROS (Robot OS)](https://wiki.ros.org)\n",
    ">   - [ROS 模擬](http://gazebosim.org)\n",
    ">   - [NVIDIA JetBot Gazebo Simulation 說明](https://discourse.ros.org/t/nvidia-jetbot-gazebo-simulation/16576)\n",
    "\n",
    "\n",
    "## <span style=\"color:blue\">Jetbot 開機設定</span>\n",
    "\n",
    "參考此篇文章 https://jetbot.org/master/index.html 執行以下指令 \n",
    "> <span style=\"color:green\">1. 下載及燒錄 image  </span>\n",
    ">   - 我用的是 4GB 的版本\n",
    ">   - 簡單判斷 2GB 或 4GB 的方式：看充電的接頭是 micro USB 的是 for Jetson Nano (4GB), 或是 USB-C (for Jetson Nano 2GB) \n",
    "\n",
    "|Platform   |JetPack Version    |JetBot Version |Download|\n",
    "|:------------- |:-------------|:-----|:-----|\n",
    "|Jetson Nano (4GB)  |4.4.1  |0.4.2  |[jetbot-042_nano-4gb-jp441.zip](https://drive.google.com/file/d/1MAX1ibJvcLulKQeMtxbjMhsrOevBfUJd/view)|\n",
    "\n",
    "> <span style=\"color:green\">2. login 的 id 跟 password 都是 jetbot  </span>\n",
    "\n",
    "> <span style=\"color:green\">3. 如果開機時進入的是 command line 模式, 可以參考以下指令, 進入 GUI 模式   </span>https://imadelhanafi.com/posts/jetson_nano_setup/\n",
    "因為, 待會兒的 examples 程式之一 teleoperation 需要用到遊戲手把 🎮 控制器, 我在 Mac 上操作 notebook 時有問題, 只有在 Jetbot 上直接執行時才 okay.\n",
    "\n",
    "```\n",
    "# disable GUI on boot\n",
    "# After applying this command, the next time you reboot it will be on terminal mode\n",
    "$ sudo systemctl set-default multi-user.target\n",
    "\n",
    "# To enable GUI again\n",
    "$ sudo systemctl set-default graphical.target\n",
    "\n",
    "```\n",
    "\n",
    "> <span style=\"color:green\">4. 設定 wifi 的 command line 指令, 要記得 reboot 才能生效  </span>\n",
    "\n",
    "```\n",
    "$ sudo nmcli device wifi connect <SSID> password <PASSWORD>\n",
    "Device 'wlan0' successfully activate with '27xxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx'.\n",
    "$\n",
    "```\n",
    "\n",
    "> <span style=\"color:green\">5. 安裝 VNC - 參考 Jetson Nano 開機畫面上的 L4T-README 目錄下的 README-vnc.txt  </span>\n",
    ">   - <span style=\"color:red\">要注意的是, vnc 需要 log in 後才能執行, 需要到系統設定內去設定 automatic log in.</span>\n",
    ">   - 執行下列 script 來安裝 vino （vnc 程式）及相關設定\n",
    ">     - 將 'thepassword' 改成你設定的密碼, 如 'jetbot'\n",
    "\n",
    "\n",
    "```\n",
    "$ sudo apt update\n",
    "$ sudo apt install vino\n",
    "\n",
    "# Enable the VNC server to start each time you log in\n",
    "$ mkdir -p ~/.config/autostart\n",
    "$ cp /usr/share/applications/vino-server.desktop ~/.config/autostart\n",
    "\n",
    "# Configure the VNC server\n",
    "$ gsettings set org.gnome.Vino prompt-enabled false\n",
    "$ gsettings set org.gnome.Vino require-encryption false\n",
    "\n",
    "# Set a password to access the VNC server\n",
    "# Replace thepassword with your desired password\n",
    "$ gsettings set org.gnome.Vino authentication-methods \"['vnc']\"\n",
    "$ gsettings set org.gnome.Vino vnc-password $(echo -n 'thepassword'|base64)\n",
    "$\n",
    "\n",
    "```\n",
    "\n",
    "> <span style=\"color:green\">6. 修改 /etc/X11/xorg.conf, 將下列設定加於檔案最後  </span>\n",
    ">    - 解析度的 1280 800 是最佳設定, 調整成其它解析度後, 無法在 Mac 上看到完整螢幕, 需要上下調整, 反而不方便\n",
    "\n",
    "```\n",
    "Section \"Screen\"\n",
    "   Identifier   \"Default Screen\"\n",
    "   Monitor      \"Configured Monitor\"\n",
    "   Device       \"Tegra0\"\n",
    "   SubSection \"Display\"\n",
    "       depth    24\n",
    "       virtual 1280 800\n",
    "   EndSubSection\n",
    "EndSection\n",
    "```\n",
    "\n",
    "> <span style=\"color:green\">7. GPIO (40 PIN expansion header) 設定  </span>\n",
    ">   - 根據官網 [Configuring the 40-pin Expansion Header](https://docs.nvidia.com/jetson/archives/l4t-archived/l4t-3231/index.html#page/Tegra%20Linux%20Driver%20Package%20Development%20Guide/hw_setup_jetson_io.html), 執行以下指令來設定硬體\n",
    ">   - 參考中文說明 [第一次用Jetson nano 就上手 - 使用40 pin GPIO](https://www.rs-online.com/designspark/jetson-nano-40-pin-gpio-cn)\n",
    ">   - 選擇 Configure 40-pin Expansion Header, 設定相關的腳位（若沒把握, 就全選）, 再選擇 Save and reboot to reconfigure pins. 重新開機後.\n",
    "\n",
    "```\n",
    "$ sudo /opt/nvidia/jetson-io/jetson-io.py\n",
    "$\n",
    "```\n",
    "> <span style=\"color:green\">8. 安裝 jtop  </span>\n",
    "> 在 Jetson 中有一個非常好用的工具就是 jtop，可以同時查看 CPU 資源與 GPU 資源，另外也可以看目前 CPU 與 GPU 的溫度與功耗，另外他還有貼心的服務，就是將你目前的 library show 出來。\n",
    "\n",
    "```\n",
    "$ sudo apt-get install python-pip python-dev build-essential \n",
    "$ sudo -H pip install jetson-stats\n",
    "$ sudo jtop\n",
    "$\n",
    "```\n",
    "\n",
    "> <span style=\"color:green\">9. 重新開機後, 先到 Jetbot 的 LED 上查看 wlan 的 IP 位址, 我查到的是 192.168.1.16   </span>\n",
    "\n",
    "> <span style=\"color:green\">10. 到 PC 或 Mac 的 browers, 打開 http://jetbot_ip_address:8888 (我的例子就是 http://192.169.1.16:8888). 或者是直接在 Jetbot 上執行, 需要進入 jetbot 的 GUI 模式, 打開 browser, 輸入 http://localhost:8888  </span>  \n",
    "\n",
    "\n",
    "\n",
    "> <span style=\"color:green\">11. Create Linux OS disk SWAP, refer to [the link](https://chtseng.wordpress.com/2019/05/01/nvida-jetson-nano-%E5%88%9D%E9%AB%94%E9%A9%97%EF%BC%9A%E5%AE%89%E8%A3%9D%E8%88%87%E6%B8%AC%E8%A9%A6/) 執行以下指令  </span>\n",
    "\n",
    "```\n",
    "# 理想的SWAP size應是RAM的二倍，但由於SD空間不是很充裕，先設定 4G 或 8G SWAP。\n",
    "$ sudo fallocate -l 8G /swapfile\n",
    "$ sudo chmod 600 /swapfile\n",
    "$ ls -lh /swapfile\n",
    "\n",
    "# 建立並啟用SWAP\n",
    "$ sudo mkswap /swapfile\n",
    "$ sudo swapon /swapfile\n",
    "$ sudo swapon –show\n",
    "\n",
    "# 輸入free -h確認已經有 4G 或 8G SWAP空間了\n",
    "free –h\n",
    "\n",
    "# 由於重開機後SWAP設定便會跑掉，因此，把SWAP加到fstab設定檔中。\n",
    "$ sudo cp /etc/fstab /etc/fstab.bak\n",
    "$ echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab\n",
    "\n",
    "```\n",
    "\n",
    "## <span style=\"color:blue\">專案啟動</span>\n",
    "\n",
    "#### <span style=\"color:red\">從 JetPack 4.4.1 （Jetbot 0.4.2) 得支援 2GB 版本, 因此 remove 不少套件, 而且從 command line 開機, 因此, 即使我們用的是 4GB 版本, 還是得安裝許多套件 </span>   \n",
    "\n",
    "> <span style=\"color:green\">1. Install Jetbot </span>\n",
    "\n",
    "```\n",
    "$ sudo apt update\n",
    "$ sudo apt install libffi-dev python3-pip\n",
    "$ sudo pip3 install ipywidgets\n",
    "$ sudo pip3 install traitlets  # package already satified\n",
    "$ cd ~/jetbot\n",
    "$ sudo python3 setup.py install\n",
    "\n",
    "```\n",
    "\n",
    "> <span style=\"color:green\">2. Install Pytorch in order to run jetbot module, the instrution can be refer to https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-7-0-now-available/72048. for latest version </span>  \n",
    "\n",
    "```\n",
    "$ sudo apt-get install libopenblas-base libopenmpi-dev \n",
    "$ pip3 install Cython\n",
    "$ wget https://nvidia.box.com/shared/static/9eptse6jyly1ggt9axbja2yrmj6pbarc.whl -O torch-1.7.0-cp36-cp36m-linux_aarch64.whl\n",
    "$ pip3 install numpy torch-1.7.0-cp36-cp36m-linux_aarch64.whl\n",
    "\n",
    "```\n",
    "\n",
    "> <span style=\"color:green\">3. CUDA 環境設定, 參考[JKJung JetPack-4.4 for Jetson Nano](https://jkjung-avt.github.io/jetpack-4.4/) 建議的 Basic set-up 的  ./install_basics.sh  </span>\n",
    "\n",
    "```\n",
    "$ git clone https://github.com/jkjung-avt/jetson_nano.git\n",
    "$ cd jetson_nano\n",
    "$ ./install_basics.sh\n",
    "$ source ${HOME}/.bashrc\n",
    "$\n",
    "```\n",
    "\n",
    "> 或是自行設定 \n",
    "\n",
    "```\n",
    "# If you used the Jetson Nano SD card image, then yes, it already has the CUDA Toolkit installed. Check under /usr/local/cuda to verify that it’s there.\n",
    "\n",
    "# Check that your ~/.bashrc file has these lines at the end, and if not, add them and restart your terminal:\n",
    "\n",
    "export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}\n",
    "export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n",
    "\n",
    "```\n",
    "> <span style=\"color:green\">4. Making sure python3 “cv2” is working</span>\n",
    "\n",
    "```\n",
    "# Install dependencies for python3 \"cv2\"\n",
    "$ sudo apt-get update\n",
    "$ sudo apt-get install -y build-essential make cmake cmake-curses-gui \\\n",
    "                          git g++ pkg-config curl libfreetype6-dev \\\n",
    "                          libcanberra-gtk-module libcanberra-gtk3-module\n",
    "$ sudo apt-get install -y python3-dev python3-testresources python3-pip\n",
    "$ sudo pip3 install -U pip Cython\n",
    "$ git clone https://github.com/jkjung-avt/jetson_nano.git\n",
    "$ cd ${HOME}/jetson_nano\n",
    "$ ./install_protobuf-3.8.0.sh    # will take hours to complete the installation\n",
    "$ sudo apt-get install protobuf-compiler libprotoc-dev\n",
    "$ sudo pip3 install numpy matplotlib==3.2.2\n",
    "\n",
    "\n",
    "# 測試 Then I tested my tegra-cam.py script with a USB webcam, and made sure the python3 “cv2” module could capture and display images properly.\n",
    "# Test tegra-cam.py (using a USB webcam)\n",
    "$ cd ~\n",
    "$ wget https://gist.githubusercontent.com/jkjung-avt/86b60a7723b97da19f7bfa3cb7d2690e/raw/3dd82662f6b4584c58ba81ecba93dd6f52c3366c/tegra-cam.py\n",
    "# 如果是用 CSI camera\n",
    "$ python3 tegra-cam.py --vid 0\n",
    "# 如果是用 USB camera\n",
    "$ python3 tegra-cam.py --usb --vid 0\n",
    "\n",
    "```\n",
    "\n",
    "> <span style=\"color:green\">5. Installing tensorflow-1.15.2  </span> NVIDIA has provided pip wheel files for both tensorflow-1.15.2 and tensorflow-2.2.0 (link). I used 1.15.2 since my TensorRT Demo #3: SSD only works for tensorflow-1.x.\n",
    "\n",
    "```\n",
    "$ sudo apt-get install -y libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran\n",
    "$ sudo pip3 install -U pip testresources setuptools\n",
    "$ sudo pip3 install -U numpy==1.16.1 future mock h5py==2.10.0 keras_preprocessing keras_applications gast==0.2.2 futures pybind11\n",
    "$ sudo pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v44 tensorflow==1.15.2\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## <span style=\"color:blue\">Car Deploying\n",
    "參考 https://github.com/jkjung-avt/tensorrt_demos Demo #5: YOLOv4 步驟執行以下指令  </span>\n",
    "\n",
    "```\n",
    "# Clone tennsorrt_demo\n",
    "$ cd ~\n",
    "$ git clone https://github.com/jkjung-avt/tensorrt_demos\n",
    "\n",
    "# 1.1 Install \"pycuda\". Note that the installation script resides in the \"ssd\" folder.\n",
    "$ cd ${HOME}/tensorrt_demos/ssd\n",
    "$ ./install_pycuda.sh\n",
    "\n",
    "# 1.2 Install version \"1.4.1\" (not the latest version) of python3 \"onnx\" module. Note that the \"onnx\" module would depend on \"protobuf\" as stated in the Prerequisite section. Reference: information provided by NVIDIA.\n",
    "$ sudo apt-get install protobuf-compiler libprotoc-dev # already the newest version\n",
    "$ sudo pip3 install onnx==1.4.1\n",
    "\n",
    "# 1.3 Go to the \"plugins/\" subdirectory and build the \"yolo_layer\" plugin. When done, a \"libyolo_layer.so\" would be generated.\n",
    "\n",
    "$ cd ${HOME}/tensorrt_demos/plugins\n",
    "$ make\n",
    "```\n",
    "\n",
    "\n",
    "## <span style=\"color:blue\">model training 訓練模型及模型轉換  </span>\n",
    "> 參考 [JK Jung 的 github ](https://github.com/jkjung-avt/yolov4_crowdhuman) 的 training on Google Colab, 及注意事項 blog [TensorRT YOLOv3 For Custom Trained Models](https://jkjung-avt.github.io/trt-yolov3-custom/)\n",
    ">    - 注意檔案命名, 檔案名稱需要包含 yolov4-416 字樣, 如 yolov4-my-416.weights 跟 yolov4-my-416.cfg 或 yolov4-416.weights 跟 yolov4-416.cfg\n",
    "\n",
    "> 1. 在 Google Colab 執行 'darknet_on_colab.ipynb' \n",
    ">   - 上傳 github <span style=\"color:green\">\n",
    "[Jetbot_YoloV4 - darknet_on_colab.ipynb](https://github.com/marconi1964/jetbot_yolov4/darknet_on_colab.ipynb) </span> ) 到 colab\n",
    ">    - remember to change runtime type to 'GPU'\n",
    ">    - 儲存模型 yolov4_my_final.weights (darknet 儲存於 /content/darknet/backup/) 跟 yolov4_my.cfg (darknet 儲存於 /content/darknet/cfg/) 到 Jetson Nano 的 ${HOME}/tensorrt_demos/yolo 下, 並改名為 yolov4-416.weights 跟 yolov4-416.cfg\n",
    "\n",
    "> - 1-1. 如果是在 Server 上執行, 參考 README_CUDA_installation.md 跟 README_training_on_server.md\n",
    ">   - 執行以下指令\n",
    "\n",
    "```\n",
    "$ git clone https://github.com/marconi1964/jetbot_yolov4.git\n",
    "$ cd jetbot_yolov4\n",
    "$ ./server_darknet_setup.sh        # don't use $ sudo ./server_darknet_setup.sh 應為這樣會安裝 darknet 在 /root 下\n",
    "$ ./server_darknet.sh\n",
    "```\n",
    "> 2. <span style=\"color:green\">Model translation from to onnx to tensorrt </span>\n",
    "\n",
    "```\n",
    "$ cd ${HOME}/tensorrt_demos/yolo\n",
    "# 將訓練模型的結果下載到此目錄下 \n",
    "$ python3 yolo_to_onnx.py -c 4 -m yolov4-416           # 我們的 catergory 有 4 個, 需要設定 -c 4 \n",
    "$ python3 onnx_to_tensorrt.py -v -c 4 -m yolov4-416    # 此轉檔需要一段時間, 打開 -v 可以看到進度\n",
    "\n",
    "```\n",
    "\n",
    "## <span style=\"color:blue\">開跑  </span>\n",
    "> 1. 下載 [github - jetbot_yolov4](https://github.com/marconi1964/jetbot_yolov4)\n",
    "> 2. 將 main.py copy 到 tensorrt_demos\n",
    "> 3. 執行 python3 jetbot_main.py\n",
    "\n",
    "```\n",
    "$ cd ~\n",
    "$ git clone https://github.com/marconi1964/jetbot_yolov4.git\n",
    "$ cp ${HOME}/jetbot_yolov4/main.py ${HOME}/tensorrt_demos\n",
    "$ cd ${HOME}/tensorrt_demos\n",
    "$ python3 jetbot_main.py\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "------------------\n",
    "## Reference\n",
    "- JK Jung / Inventec\n",
    "    - [PPT - Applications of Real-time Object Detection on NVIDIA Jetson TX2](https://on-demand.gputechconf.com/gtc-taiwan/2018/pdf/1-7_General%20Speaker_Inventec_PDF%20For%20Sharing.pdf)\n",
    "    - Github : https://github.com/jkjung-avt/\n",
    "    - Github : [Training a DarkNet YOLOv4 model for custimized dataset](https://github.com/jkjung-avt/yolov4_crowdhuman)\n",
    "    - Blog : https://jkjung-avt.github.io/\n",
    "    - Blog : [TensorRT YOLOv3 For Custom Trained Models](https://jkjung-avt.github.io/trt-yolov3-custom/)\n",
    "- 參考 [Derek 同學的 github](https://github.com/derekhsu/jetbot_yolov4)\n",
    "- 寫完後, 不小心發現一篇美女寫的文章, [YOLOv4訓練教學](https://medium.com/ching-i/yolo-c49f70241aa7). 她這一篇絕對比我寫的有吸引力."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
